<html>
<head>
<title>Mnist_Classification.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #7a7e85;}
.s1 { color: #bcbec4;}
.s2 { color: #cf8e6d;}
.s3 { color: #bcbec4;}
.s4 { color: #2aacb8;}
.s5 { color: #6aab73;}
</style>
</head>
<body bgcolor="#1e1f22">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Mnist_Classification.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">#%% md 
</span><span class="s1"># MNIST Digit Classification 
 
This notebook demonstrates the process of classifying handwritten digits using the MNIST dataset. Start by importing necessary libraries and modules. This includes `sklearn` for dataset loading and splitting, `keras` for data preprocessing, and `matplotlib` for visualization. 
 
## Import Libraries 
 
</span><span class="s0">#%% 
</span><span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">datasets </span><span class="s2">import </span><span class="s1">load_digits</span>
<span class="s2">from </span><span class="s1">sklearn</span><span class="s3">.</span><span class="s1">model_selection </span><span class="s2">import </span><span class="s1">train_test_split</span>
<span class="s2">from </span><span class="s1">keras</span><span class="s3">.</span><span class="s1">utils </span><span class="s2">import </span><span class="s1">to_categorical</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">matplotlib</span><span class="s3">.</span><span class="s1">pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<span class="s3">%</span><span class="s1">matplotlib inline</span>
<span class="s0">#%% md 
</span><span class="s1">## Loading the MNIST Dataset 
 
load the MNIST dataset and examine its keys to understand the data structure.  
 
</span><span class="s0">#%% 
</span><span class="s1">mnist </span><span class="s3">= </span><span class="s1">load_digits</span><span class="s3">()</span>
<span class="s1">mnist</span><span class="s3">.</span><span class="s1">keys</span><span class="s3">()</span>
<span class="s0">#%% md 
</span><span class="s1">## Data Exploration 
 
Converting the data into a pandas DataFrame for better visualization and analysis. Displaying the first few rows of the dataset to get an idea of the data. 
 
</span><span class="s0">#%% 
</span><span class="s1">data_mnist </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">mnist</span><span class="s3">.</span><span class="s1">data</span><span class="s3">)</span>
<span class="s1">data_mnist</span><span class="s3">.</span><span class="s1">head</span><span class="s3">()</span>
<span class="s0">#%% md 
</span><span class="s1">## Data Preparation 
 
Converting the data into a numpy array, which will be used for training the machine learning model. 
 
</span><span class="s0">#%% 
</span><span class="s1">data </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span><span class="s1">data_mnist</span><span class="s3">)</span>
<span class="s0">#%% 
</span><span class="s1">target_mnist </span><span class="s3">= </span><span class="s1">pd</span><span class="s3">.</span><span class="s1">DataFrame</span><span class="s3">(</span><span class="s1">mnist</span><span class="s3">.</span><span class="s1">target</span><span class="s3">)</span>
<span class="s1">target_mnist</span><span class="s3">.</span><span class="s1">head</span><span class="s3">()</span>
<span class="s0">#%% 
</span><span class="s1">target </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">array</span><span class="s3">(</span><span class="s1">target_mnist</span><span class="s3">)</span>
<span class="s0">#%% 
</span><span class="s1">m</span><span class="s3">, </span><span class="s1">n </span><span class="s3">= </span><span class="s1">data_mnist</span><span class="s3">.</span><span class="s1">shape</span>
<span class="s1">plt</span><span class="s3">.</span><span class="s1">imshow</span><span class="s3">(</span><span class="s1">mnist</span><span class="s3">.</span><span class="s1">images</span><span class="s3">[</span><span class="s4">0</span><span class="s3">])</span>
<span class="s1">print</span><span class="s3">(</span><span class="s1">m</span><span class="s3">, </span><span class="s1">n</span><span class="s3">)</span>
<span class="s0">#%% 
</span><span class="s1">fig</span><span class="s3">, </span><span class="s1">axes </span><span class="s3">= </span><span class="s1">plt</span><span class="s3">.</span><span class="s1">subplots</span><span class="s3">(</span><span class="s4">2</span><span class="s3">, </span><span class="s4">10</span><span class="s3">, </span><span class="s1">figsize</span><span class="s3">=(</span><span class="s4">16</span><span class="s3">, </span><span class="s4">6</span><span class="s3">))</span>
<span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s4">20</span><span class="s3">):</span>
    <span class="s1">axes</span><span class="s3">[</span><span class="s1">i</span><span class="s3">//</span><span class="s4">10</span><span class="s3">, </span><span class="s1">i </span><span class="s3">%</span><span class="s4">10</span><span class="s3">].</span><span class="s1">imshow</span><span class="s3">(</span><span class="s1">mnist</span><span class="s3">.</span><span class="s1">images</span><span class="s3">[</span><span class="s1">i</span><span class="s3">], </span><span class="s1">cmap</span><span class="s3">=</span><span class="s5">'gray'</span><span class="s3">)</span>
    <span class="s1">axes</span><span class="s3">[</span><span class="s1">i</span><span class="s3">//</span><span class="s4">10</span><span class="s3">, </span><span class="s1">i </span><span class="s3">%</span><span class="s4">10</span><span class="s3">].</span><span class="s1">axis</span><span class="s3">(</span><span class="s5">'off'</span><span class="s3">)</span>
    <span class="s1">axes</span><span class="s3">[</span><span class="s1">i</span><span class="s3">//</span><span class="s4">10</span><span class="s3">, </span><span class="s1">i </span><span class="s3">%</span><span class="s4">10</span><span class="s3">].</span><span class="s1">set_title</span><span class="s3">(</span><span class="s5">f&quot;target: </span><span class="s2">{</span><span class="s1">mnist</span><span class="s3">.</span><span class="s1">target</span><span class="s3">[</span><span class="s1">i</span><span class="s3">]</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
    
<span class="s1">plt</span><span class="s3">.</span><span class="s1">tight_layout</span><span class="s3">()</span>
<span class="s0">#%% md 
</span><span class="s1">## Train-Test Split 
 
Splitting the dataset into training and test sets.  
Turning labels into categorical values by utilizing kera's library 
 
</span><span class="s0">#%% 
# Get 60% of the dataset as the training set. Put the remaining 40% in temporary variables: x_temp and y_temp.</span>
<span class="s1">x_train</span><span class="s3">, </span><span class="s1">x_temp</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s1">y_temp </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span><span class="s1">data</span><span class="s3">, </span><span class="s1">target</span><span class="s3">, </span><span class="s1">test_size </span><span class="s3">= </span><span class="s4">0.4</span><span class="s3">, </span><span class="s1">random_state </span><span class="s3">= </span><span class="s4">1</span><span class="s3">)</span>

<span class="s0"># Split the 40% subset above into two: one half for cross validation and the other for the test set</span>
<span class="s1">x_cv</span><span class="s3">, </span><span class="s1">x_test</span><span class="s3">, </span><span class="s1">y_cv</span><span class="s3">, </span><span class="s1">y_test </span><span class="s3">= </span><span class="s1">train_test_split</span><span class="s3">(</span><span class="s1">x_temp</span><span class="s3">, </span><span class="s1">y_temp</span><span class="s3">, </span><span class="s1">test_size</span><span class="s3">=</span><span class="s4">0.50</span><span class="s3">, </span><span class="s1">random_state</span><span class="s3">=</span><span class="s4">1</span><span class="s3">)</span>
<span class="s0">#%% 
# Delete temporary variables</span>
<span class="s2">del </span><span class="s1">x_temp</span><span class="s3">, </span><span class="s1">y_temp</span>
<span class="s1">x_train </span><span class="s3">= </span><span class="s1">x_train</span><span class="s3">.</span><span class="s1">T</span>
<span class="s1">x_cv </span><span class="s3">= </span><span class="s1">x_cv</span><span class="s3">.</span><span class="s1">T</span>
<span class="s1">x_test </span><span class="s3">= </span><span class="s1">x_test</span><span class="s3">.</span><span class="s1">T</span>

<span class="s1">y_train </span><span class="s3">= </span><span class="s1">y_train</span><span class="s3">.</span><span class="s1">T</span>
<span class="s1">y_cv </span><span class="s3">= </span><span class="s1">y_cv</span><span class="s3">.</span><span class="s1">T</span>
<span class="s1">y_test </span><span class="s3">= </span><span class="s1">y_test</span><span class="s3">.</span><span class="s1">T</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the training set (input) is: </span><span class="s2">{</span><span class="s1">x_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the training set (target) is: </span><span class="s2">{</span><span class="s1">y_train</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}\n</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the cross validation set (input) is: </span><span class="s2">{</span><span class="s1">x_cv</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the cross validation set (target) is: </span><span class="s2">{</span><span class="s1">y_cv</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}\n</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the test set (input) is: </span><span class="s2">{</span><span class="s1">x_test</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;the shape of the test set (target) is: </span><span class="s2">{</span><span class="s1">y_test</span><span class="s3">.</span><span class="s1">shape</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">one_hot</span><span class="s3">(</span><span class="s1">Y</span><span class="s3">):</span>
    <span class="s1">one_hot_Y </span><span class="s3">= </span><span class="s1">to_categorical</span><span class="s3">(</span><span class="s1">Y</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]) </span><span class="s0">#The target data set is 2D array, therefore needs Y[0]</span>
    <span class="s1">one_hot_Y </span><span class="s3">= </span><span class="s1">one_hot_Y</span><span class="s3">.</span><span class="s1">T</span>
    <span class="s2">return </span><span class="s1">one_hot_Y</span>
<span class="s0">#%% md 
</span><span class="s1">## Model Definition 
 
Defining the architecture of the neural network model. This includes initializing model parameters, setting up the layer functions, forward prop, backward prop and gradient descent. 
 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">init_param</span><span class="s3">():</span>
    <span class="s1">W1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">10</span><span class="s3">, </span><span class="s4">64</span><span class="s3">) / </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sqrt</span><span class="s3">(</span><span class="s4">74</span><span class="s3">)</span>
    <span class="s1">b1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">10</span><span class="s3">, </span><span class="s4">1</span><span class="s3">) / </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sqrt</span><span class="s3">(</span><span class="s4">11</span><span class="s3">)</span>
    <span class="s1">W2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">10</span><span class="s3">, </span><span class="s4">10</span><span class="s3">) / </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sqrt</span><span class="s3">(</span><span class="s4">20</span><span class="s3">)</span>
    <span class="s1">b2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">random</span><span class="s3">.</span><span class="s1">randn</span><span class="s3">(</span><span class="s4">10</span><span class="s3">, </span><span class="s4">1</span><span class="s3">) / </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sqrt</span><span class="s3">(</span><span class="s4">11</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">W1</span><span class="s3">, </span><span class="s1">b1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">b2</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">ReLU</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">):</span>
    <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">maximum</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">, </span><span class="s4">0</span><span class="s3">)</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">Softmax</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">):</span>
    <span class="s1">a </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">) / </span><span class="s1">sum</span><span class="s3">(</span><span class="s1">np</span><span class="s3">.</span><span class="s1">exp</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">))</span>
    <span class="s2">return </span><span class="s1">a</span>
<span class="s0">#%% 
# First layer of ReLU, Second layer of Softmax</span>
<span class="s2">def </span><span class="s1">forward_prop</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
    <span class="s1">Z1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">X</span><span class="s3">) + </span><span class="s1">B1</span>
    <span class="s1">A1 </span><span class="s3">= </span><span class="s1">ReLU</span><span class="s3">(</span><span class="s1">Z1</span><span class="s3">)</span>
    <span class="s1">Z2 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">W2</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">) + </span><span class="s1">B2</span>
    <span class="s1">A2 </span><span class="s3">= </span><span class="s1">Softmax</span><span class="s3">(</span><span class="s1">Z2</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">Z1</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">, </span><span class="s1">Z2</span><span class="s3">, </span><span class="s1">A2</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">deriv_ReLU</span><span class="s3">(</span><span class="s1">Z</span><span class="s3">):</span>
    <span class="s2">return </span><span class="s1">Z </span><span class="s3">&gt; </span><span class="s4">0</span>
<span class="s0">#%% md 
</span><span class="s1">## The following Latex shows the Backward Propagation Calculation for the function. 
</span><span class="s0">#%% md 
</span><span class="s1">$$ 
\text{Back Propagation Calculation} 
\\ 
\text{The loss function L is defined below} 
\\ 
L = - \sum_{i}{y_i * ln(a_i)} 
\\ 
y_i \text{ is the true label 0/1 for the corresponding softmax activation output } a_i 
\\ 
\frac{\partial L}{\partial Z_i} = -(\frac{y_i}{a_i} * \frac{\partial a_i}{\partial Z_i} + \sum_{k \neq i}{\frac{y_k}{a_k} * \frac{\partial a_k}{\partial Z_i}}) 
\\ 
\text{The derivative is seperated to two parts because there's two circumstance \\ which the input Z's index is equal to y's index and the input Z's index is different to y's index} 
\\ 
\frac{\partial L}{\partial Z_i} = a_i - y_i 
\\ 
\\ 
Z_2 = W_2 * A_1 + B_2 
\\ 
\frac{\partial L}{\partial W_2} = \frac{\partial L}{\partial Z_2} * \frac{\partial Z_2}{\partial W_2} 
=(a_2 - y_i) * a_1 
\\ 
\frac{\partial L}{\partial B_2} = \frac{\partial L}{\partial Z_2} * \frac{\partial Z_2}{\partial B_2} = (a_2 - y_i) * 1 
\\ 
\frac{\partial L}{\partial Z_1} = \frac{\partial L}{\partial Z_2} * \frac{\partial Z_2}{\partial a_2} * \frac{\partial a_2}{\partial Z_1} = (a_2 - y_i) * W_2 * ReLU'(Z1) 
\\ 
\frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial Z_2} * \frac{\partial Z_2}{\partial a_2} * \frac{\partial a_2}{\partial Z_1} * \frac{\partial Z_1}{\partial W_1} = \frac{\partial L}{\partial Z_1} * X 
\\ 
\frac{\partial L}{\partial W_1} = \frac{\partial L}{\partial Z_2} * \frac{\partial Z_2}{\partial a_2} * \frac{\partial a_2}{\partial Z_1} * \frac{\partial Z_1}{\partial W_1} = \frac{\partial L}{\partial Z_1} * 1 
\\ 
\text{The Cost function will be the average of the sum of the loss function} 
$$ 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">back_prop</span><span class="s3">(</span><span class="s1">Z1</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">A2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">Y</span><span class="s3">):</span>
    <span class="s1">one_hot_Y </span><span class="s3">= </span><span class="s1">one_hot</span><span class="s3">(</span><span class="s1">Y</span><span class="s3">)</span>
    <span class="s1">dCost_dZ2 </span><span class="s3">= </span><span class="s1">A2 </span><span class="s3">- </span><span class="s1">one_hot_Y</span>
    <span class="s1">dCost_dW2 </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ </span><span class="s1">m </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">dCost_dZ2</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">.</span><span class="s1">T</span><span class="s3">)</span>
    <span class="s1">dCost_dB2 </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ </span><span class="s1">m </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">dCost_dZ2</span><span class="s3">)</span>
    
    <span class="s1">dCost_dZ1 </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">W2</span><span class="s3">.</span><span class="s1">T</span><span class="s3">, </span><span class="s1">dCost_dZ2</span><span class="s3">) * </span><span class="s1">deriv_ReLU</span><span class="s3">(</span><span class="s1">Z1</span><span class="s3">)</span>
    <span class="s1">dCost_dW1 </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ </span><span class="s1">m </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">dot</span><span class="s3">(</span><span class="s1">dCost_dZ1</span><span class="s3">, </span><span class="s1">X</span><span class="s3">.</span><span class="s1">T</span><span class="s3">)</span>
    <span class="s1">dCost_dB1 </span><span class="s3">= </span><span class="s4">1 </span><span class="s3">/ </span><span class="s1">m </span><span class="s3">* </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">dCost_dZ1</span><span class="s3">)</span>
    
    <span class="s2">return </span><span class="s1">dCost_dW2</span><span class="s3">, </span><span class="s1">dCost_dB2</span><span class="s3">, </span><span class="s1">dCost_dW1</span><span class="s3">, </span><span class="s1">dCost_dB1  </span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">gradient_descent</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">dW1</span><span class="s3">, </span><span class="s1">dB1</span><span class="s3">, </span><span class="s1">dW2</span><span class="s3">, </span><span class="s1">dB2</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">):</span>
    <span class="s1">W1 </span><span class="s3">= </span><span class="s1">W1 </span><span class="s3">- </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">dW1 </span>
    <span class="s1">B1 </span><span class="s3">= </span><span class="s1">B1 </span><span class="s3">- </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">dB1 </span>
    <span class="s1">W2 </span><span class="s3">= </span><span class="s1">W2 </span><span class="s3">- </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">dW2</span>
    <span class="s1">B2 </span><span class="s3">= </span><span class="s1">B2 </span><span class="s3">- </span><span class="s1">alpha </span><span class="s3">* </span><span class="s1">dB2</span>
    <span class="s2">return </span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">prediction</span><span class="s3">(</span><span class="s1">A2</span><span class="s3">):</span>
    <span class="s1">predict </span><span class="s3">= </span><span class="s1">np</span><span class="s3">.</span><span class="s1">argmax</span><span class="s3">(</span><span class="s1">A2</span><span class="s3">, </span><span class="s4">0</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">predict</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">accuracy</span><span class="s3">(</span><span class="s1">predict</span><span class="s3">, </span><span class="s1">Y</span><span class="s3">):</span>
    <span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;Predict : </span><span class="s2">{</span><span class="s1">predict</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
    <span class="s1">print</span><span class="s3">(</span><span class="s5">f&quot;True Label : </span><span class="s2">{</span><span class="s1">Y</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]</span><span class="s2">}</span><span class="s5">&quot;</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">np</span><span class="s3">.</span><span class="s1">sum</span><span class="s3">(</span><span class="s1">predict </span><span class="s3">== </span><span class="s1">Y</span><span class="s3">[</span><span class="s4">0</span><span class="s3">]) / </span><span class="s1">Y</span><span class="s3">[</span><span class="s4">0</span><span class="s3">].</span><span class="s1">size</span>
<span class="s0">#%% md 
</span><span class="s1">## Model Training 
 
Training the model on the training data. Feeding the training data through the model and adjusting the model weights based on the loss. 
 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">train</span><span class="s3">(</span><span class="s1">X</span><span class="s3">, </span><span class="s1">Y</span><span class="s3">, </span><span class="s1">iterations</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">):</span>
    <span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2 </span><span class="s3">= </span><span class="s1">init_param</span><span class="s3">()</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range</span><span class="s3">(</span><span class="s1">iterations</span><span class="s3">):</span>
        <span class="s1">Z1</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">, </span><span class="s1">Z2</span><span class="s3">, </span><span class="s1">A2 </span><span class="s3">= </span><span class="s1">forward_prop</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">)</span>
        <span class="s1">dW2</span><span class="s3">, </span><span class="s1">dB2</span><span class="s3">, </span><span class="s1">dW1</span><span class="s3">, </span><span class="s1">dB1 </span><span class="s3">= </span><span class="s1">back_prop</span><span class="s3">(</span><span class="s1">Z1</span><span class="s3">, </span><span class="s1">A1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">A2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">, </span><span class="s1">Y</span><span class="s3">)</span>
        <span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2 </span><span class="s3">= </span><span class="s1">gradient_descent</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">dW1</span><span class="s3">, </span><span class="s1">dB1</span><span class="s3">, </span><span class="s1">dW2</span><span class="s3">, </span><span class="s1">dB2</span><span class="s3">, </span><span class="s1">alpha</span><span class="s3">)</span>
        <span class="s2">if </span><span class="s1">i </span><span class="s3">% </span><span class="s4">1000 </span><span class="s3">== </span><span class="s4">0</span><span class="s3">:</span>
            <span class="s1">print</span><span class="s3">(</span><span class="s5">&quot;Epoch&quot;</span><span class="s3">, </span><span class="s1">i</span><span class="s3">)</span>
            <span class="s1">print</span><span class="s3">(</span><span class="s5">&quot;Accuracy: &quot;</span><span class="s3">, </span><span class="s1">accuracy</span><span class="s3">(</span><span class="s1">prediction</span><span class="s3">(</span><span class="s1">A2</span><span class="s3">), </span><span class="s1">Y</span><span class="s3">))</span>
    
    <span class="s2">return </span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span>
<span class="s0">#%% md 
</span><span class="s1">## Starting to train the model with 50000 iterations and learning rate of 0.001 
</span><span class="s0">#%% 
</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2 </span><span class="s3">= </span><span class="s1">train</span><span class="s3">(</span><span class="s1">x_train</span><span class="s3">, </span><span class="s1">y_train</span><span class="s3">, </span><span class="s4">50000</span><span class="s3">, </span><span class="s4">0.001</span><span class="s3">)</span>
<span class="s0">#%% md 
</span><span class="s1">## Defining a prediction function to test the cv set. 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">make_predictions</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">):</span>
    <span class="s1">_</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">_</span><span class="s3">, </span><span class="s1">A2 </span><span class="s3">= </span><span class="s1">forward_prop</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">X</span><span class="s3">)</span>
    <span class="s1">predictions </span><span class="s3">= </span><span class="s1">prediction</span><span class="s3">(</span><span class="s1">A2</span><span class="s3">)</span>
    <span class="s2">return </span><span class="s1">predictions</span>
<span class="s0">#%% 
</span><span class="s1">cv_predictions </span><span class="s3">= </span><span class="s1">make_predictions</span><span class="s3">(</span><span class="s1">W1</span><span class="s3">, </span><span class="s1">B1</span><span class="s3">, </span><span class="s1">W2</span><span class="s3">, </span><span class="s1">B2</span><span class="s3">, </span><span class="s1">x_cv</span><span class="s3">)</span>
<span class="s1">print</span><span class="s3">(</span><span class="s1">accuracy</span><span class="s3">(</span><span class="s1">cv_predictions</span><span class="s3">, </span><span class="s1">y_cv</span><span class="s3">))</span></pre>
</body>
</html>